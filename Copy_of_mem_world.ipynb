{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNVC+AskSsj2eF6mgvjlBF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sallumandya1995/meme_world/blob/main/Copy_of_mem_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/spaces/Xhaheen/meme_world\n",
        "%cd  /content/meme_world"
      ],
      "metadata": {
        "id": "7zaCc934lyEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Step 1: Install the necessary packages\n",
        "!pip install gradio\n",
        "!pip install openai\n",
        "!pip install transformers\n",
        "!pip install Pillow"
      ],
      "metadata": {
        "id": "2634b9USglxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0sFfXP8fqiV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Step 2: Set up the Gradio interface and import necessary packages\n",
        "import gradio as gr\n",
        "import openai\n",
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "# Step 3: Load the provided image captioning model\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Step 4: Create a function to generate captions from images\n",
        "max_length = 16\n",
        "num_beams = 4\n",
        "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
        "\n",
        "def generate_caption(image):\n",
        "    image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(mode=\"RGB\")\n",
        "    pixel_values = feature_extractor(images=[image], return_tensors=\"pt\").pixel_values\n",
        "    pixel_values = pixel_values.to(device)\n",
        "    output_ids = model.generate(pixel_values, **gen_kwargs)\n",
        "    caption = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
        "    return caption\n",
        "\n",
        "\n",
        "# Step 5: Create a function to generate memes using the GPT-3 API\n",
        "def generate_meme(caption, department):\n",
        "    openai.api_key = \"sk- \"\n",
        "    prompt = f\"Create a non-offensive meme caption for the following image description in the context of {department} department: {caption}\"\n",
        "    response = openai.Completion.create(engine=\"text-davinci-002\", prompt=prompt, max_tokens=50, n=1, stop=None, temperature=0.7)\n",
        "    meme_caption = response.choices[0].text.strip()\n",
        "    return meme_caption\n",
        "\n",
        "# Step 6: Define the main meme generation function\n",
        "def meme_generator(image, department):\n",
        "    caption = generate_caption(image)\n",
        "    meme_caption = generate_meme(caption, department)\n",
        "    return meme_caption\n",
        "\n",
        "examples = [f\"example{i}.png\" for i in range(1,7)]\n",
        "\n",
        "# Step 7: Launch the Gradio application\n",
        "image_input = gr.inputs.Image()\n",
        "department_input = gr.inputs.Dropdown(choices=[\"data science\", \"product management\",\"marketing\",\"startup\" ,\"agile\",\"crypto\" , \"SEO\" ])\n",
        "output_text = gr.outputs.Textbox()\n",
        "\n",
        "gr.Interface(fn=meme_generator, inputs=[image_input, department_input], outputs=output_text, title=\"Meme world!\",description= \" Looking for a fun and easy way to generate memes? Look no further than Meme world! Leveraging large language models like GPT-3PT-3  / Ai21 / Cohere, you can create memes that are sure to be a hit with your friends or network. Created with ♥️ by Arsalan @[Xaheen](https://www.linkedin.com/in/sallu-mandya/). kindly share your thoughts in discussion session and use the app responsibly #NO_Offense \\n \\n built with ❤️   @[Xhaheen](https://www.linkedin.com/in/sallu-mandya/)\",        theme=\"grass\",\n",
        "    \n",
        "        examples =[['example5.png','data science' ],\n",
        "            ['example2.png','product management'],\n",
        "            ['example3.png','startup'],\n",
        "            ['example4.png','marketing'],\n",
        "            ['example1.png','agile'],\n",
        "            ['example6.png','crypto']]).launch(debug=True)\n"
      ]
    }
  ]
}